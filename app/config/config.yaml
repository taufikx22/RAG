embedding:
  default_model: all-MiniLM-L6-v2
generation:
  default_model: gemini-2.0-flash-exp
  default_type: gemini
  models:
  - max_tokens: 1024
    model: gpt-3.5-turbo
    temperature: 0.2
    type: openai
  - max_tokens: 1024
    model: gemini-2.0-flash-exp
    temperature: 0.2
    type: gemini
retrieval:
  default_strategy: semantic
  strategies:
    hybrid:
      semantic_weight: 0.7
    reranking:
      final_top_k: 5
      initial_top_k: 20
      model: cross-encoder/ms-marco-MiniLM-L-6-v2
    semantic: {}
vector_store:
  default: chroma
  options:
    chroma:
      collection_name: documents
      persist_directory: ./data/chroma_db
    qdrant:
      collection_name: documents
      url: http://localhost:6333
      vector_size: 384